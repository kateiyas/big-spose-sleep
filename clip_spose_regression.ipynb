{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "477a1e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import MultiTaskElasticNet, Ridge, RidgeCV, ElasticNet, ElasticNetCV, Lasso, MultiTaskLassoCV\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error, r2_score, explained_variance_score, mean_absolute_percentage_error\n",
    "from scipy.io import loadmat, savemat\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from big_sleep.clip import load\n",
    "from big_sleep.big_spose_sleep import create_clip_img_transform\n",
    "import glob\n",
    "import torch\n",
    "from os.path import exists\n",
    "from ridge import ridge, ridge_corr, bootstrap_ridge\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe86d78",
   "metadata": {},
   "source": [
    "## Extract CLIP features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cdfe5a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "thingsroot = \"/Users/katja/Documents/Data/THINGS/\"\n",
    "\n",
    "#thingscats = [catdir.split(\"/\")[-1] for catdir in glob.glob(thingsroot+\"/images/*\")]\n",
    "thingsimgfns = thingsroot+\"/images/{}/*.*\"\n",
    "\n",
    "regr_data_fn = \"../data_spose_to_clip.mat\"\n",
    "\n",
    "reextract_data = False\n",
    "\n",
    "thingscats = []\n",
    "with open(thingsroot+\"THINGS_unique_IDs.txt\", 'r') as handle:\n",
    "    lines = handle.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if len(line)>0:\n",
    "            thingscats.append(line)\n",
    "\n",
    "assert(len(thingscats)==1854)\n",
    "\n",
    "spose_cat_emb = np.loadtxt(thingsroot+\"spose_embedding_49d_sorted.txt\")\n",
    "\n",
    "assert(len(thingscats)==spose_cat_emb.shape[0])\n",
    "\n",
    "#num_imgs = 0\n",
    "#for thingscat in thingscats:\n",
    "#    thingscatimgfns = glob.glob(thingsimgfns.format(thingscat))\n",
    "#    num_imgs += len(thingscatimgfns)\n",
    "#print(\"Number of THINGS images found:\", num_imgs)\n",
    "    \n",
    "clip_perceptor, _ = load('ViT-B/32', jit = False)\n",
    "clip_transform = create_clip_img_transform(224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4c5ac2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of THINGS images found: 26107\n",
      "Compose(\n",
      "    Resize(size=224, interpolation=PIL.Image.BILINEAR)\n",
      "    CenterCrop(size=(224, 224))\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "thingsimgs = datasets.ImageFolder(thingsroot+'/images/', transform=clip_transform)\n",
    "thingsloader = torch.utils.data.DataLoader(thingsimgs, batch_size=1, shuffle=False)\n",
    "\n",
    "print(\"Number of THINGS images found:\", len(thingsloader))\n",
    "\n",
    "print(clip_transform)\n",
    "\n",
    "num_imgs = len(thingsloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "549f4685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through it, get a batch on each loop \n",
    "show_num = 50\n",
    "for i, (thingsimg, catID) in enumerate(thingsloader): \n",
    "    #print(thingscats[catID])\n",
    "    #print(thingsimg.shape)\n",
    "    if i > show_num:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fbbe603e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.2 ms, sys: 36.1 ms, total: 54.3 ms\n",
      "Wall time: 60.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if not exists(regr_data_fn) and reextract_data:\n",
    "    # CPU times: user 1h 7min 42s, sys: 2min 53s, total: 1h 10min 36s\n",
    "    # Wall time: 1h 8min 37s\n",
    "\n",
    "    x_spose_vecs = np.zeros([num_imgs,49])  # X: SPoSE vectors (same for each cat)\n",
    "    y_clip_vecs = np.zeros([num_imgs,512])  # Y: clip vectors\n",
    "\n",
    "    # Load data\n",
    "    img_i = 0\n",
    "    for i, (thingsimg, catID) in enumerate(thingsloader):\n",
    "\n",
    "        x_spose_vecs[i,:] = spose_cat_emb[catID,:] \n",
    "        y_clip_vecs[i,:] = clip_perceptor.encode_image(thingsimg).detach().numpy().squeeze()\n",
    "\n",
    "        img_i += 1\n",
    "\n",
    "    savemat(regr_data_fn, {\"x_spose\":x_spose_vecs, \"y_clip\":y_clip_vecs})\n",
    "else: \n",
    "    regr_data = loadmat(regr_data_fn)\n",
    "    x_spose_vecs = regr_data[\"x_spose\"]\n",
    "    y_clip_vecs = regr_data[\"y_clip\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "662f2d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (26107, 49)\n",
      "Y shape: (26107, 512)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", x_spose_vecs.shape)\n",
    "print(\"Y shape:\", y_clip_vecs.shape)\n",
    "\n",
    "xspose_train, xspose_test, yclip_train, yclip_test = train_test_split( x_spose_vecs, \n",
    "                                                                       y_clip_vecs, \n",
    "                                                                       test_size=0.10, \n",
    "                                                                       random_state=42)\n",
    "\n",
    "xclip_train, xclip_test, yspose_train, yspose_test = train_test_split( y_clip_vecs, \n",
    "                                                                       x_spose_vecs, \n",
    "                                                                       test_size=0.10, \n",
    "                                                                       random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1a4e20d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # scaling\n",
    "    scaler = StandardScaler()\n",
    "    xspose_train = scaler.fit_transform(xspose_train)\n",
    "    xspose_test = scaler.fit_transform(xspose_test)\n",
    "    \n",
    "    xclip_train = scaler.fit_transform(xclip_train)\n",
    "    xclip_test = scaler.fit_transform(xclip_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "53ef7220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Ridge SPoSE-to-CLIP R2: 0.48681972609016083\n"
     ]
    }
   ],
   "source": [
    "# checking data for issues by doing CLIP-to-SPoSE (which is supposed to work)\n",
    "model = Ridge()\n",
    "model.fit(xclip_train, yspose_train)\n",
    "yspose_test_pred = model.predict(xclip_test)\n",
    "\n",
    "print(\"Default Ridge SPoSE-to-CLIP R2:\", r2_score(yspose_test, yspose_test_pred))\n",
    "\n",
    "# TODO: find best\n",
    "# TODO: determine best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "aff3c045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5152470793049417"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking data for issues by doing CLIP-to-SPoSE (which is supposed to work)\n",
    "model = RidgeCV()\n",
    "clf = model.fit(xclip_train, yspose_train)\n",
    "clf.score(xclip_train, yspose_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5eced885",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt, corr, valphas, bscorrs, valinds = bootstrap_ridge(xclip_train, yspose_train, \n",
    "                                                      xclip_test, yspose_test,\n",
    "                                                      alphas=np.logspace(-100, 100, 60),\n",
    "                                                      nboots=5,\n",
    "                                                      chunklen=10, nchunks=15, return_wt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d98142c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42757745111063405\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(corr))  # 0.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171f9c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "87a15449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 512)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "96b7fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt, corr, valphas, bscorrs, valinds = bootstrap_ridge(xspose_train, yclip_train, \n",
    "                                                      xspose_test, yclip_test,\n",
    "                                                      alphas=np.logspace(-2, 100, 100),\n",
    "                                                      nboots=5,\n",
    "                                                      chunklen=10, nchunks=15, return_wt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "30ba7a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.795284011669666"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa6ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7017817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on all data\n",
    "wt, corr, valphas, bscorrs, valinds = bootstrap_ridge(x_spose_vecs, y_clip_vecs, \n",
    "                                                      xspose_test, yclip_test,\n",
    "                                                      alphas=np.logspace(-2, 100, 100),\n",
    "                                                      nboots=5,\n",
    "                                                      chunklen=10, nchunks=15, return_wt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "90b8964d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42767548855293525\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(corr))  # 0.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "21822b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat('big_sleep/data/W_aridge_spose_to_clip.mat', {'W':wt} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4de8bc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5128427207844467"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking data for issues by doing CLIP-to-SPoSE (which is supposed to work)\n",
    "model = MultiTaskLassoCV()\n",
    "clf = model.fit(xclip_train, yspose_train)\n",
    "clf.score(xclip_train, yspose_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d8a03476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5127160482374192"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking data for issues by doing CLIP-to-SPoSE (which is supposed to work)\n",
    "model = MultiTaskElasticNetCV()\n",
    "clf = model.fit(xclip_train, yspose_train)\n",
    "clf.score(xclip_train, yspose_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38004cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: set up modeling with CLIP-to-spose\n",
    "\n",
    "# TODO: standard scaler\n",
    "# TODO: compare regression methods: https://towardsdatascience.com/quickly-test-multiple-models-a98477476f0\n",
    "# TODO: determine best parameters via CV\n",
    "# TODO: try alexridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b1db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: set up modeling with CLIP-to-spose\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3c193ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiTaskElasticNet()\n",
    "model.fit(xspose_train, yclip_train)\n",
    "yclip_test_pred = model.predict(xspose_test)\n",
    "\n",
    "# TODO: determine best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "464b1f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiTaskLasso()\n",
    "model.fit(xspose_train, yclip_train)\n",
    "yclip_test_pred = model.predict(xspose_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96a274e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#yclip_test_pred = MultiOutputRegressor(GradientBoostingRegressor(random_state=0)).fit(xspose_train, yclip_train).predict(xspose_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6318cd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(yclip_test, yclip_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907e413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()  # TODO: elasticNet\n",
    "# fit model\n",
    "model.fit(X, y)\n",
    "# make a prediction\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# force the scores to be positive\n",
    "n_scores = absolute(n_scores)\n",
    "# summarize performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a1360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statistics import mean\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df,target,test_size=0.3)\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(X_train)\n",
    "scaled_x_test = scaler.fit_transform(X_test)\n",
    "regression = LinearRegression()\n",
    "model = regression.fit(features, Y_train)\n",
    "preds = model.predict(scaled_x_test)\n",
    "\n",
    "mean(cross_val_score(regression, preds.reshape(-1,1), Y_test, cv=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b27c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ensemble randomforest\n",
    "# TODO: test model accuracy\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "regressor = xgb.XGBRegressor(\n",
    "    learning_rate=0.01,\n",
    "    colsample_bytree=0.8,\n",
    "    n_estimators=430,\n",
    "    reg_lambda=1,\n",
    "    gamma=1,\n",
    "    max_depth=3,\n",
    "    subsample=0.55\n",
    ")\n",
    "model = regressor.fit(features,Y_train)\n",
    "preds = regressor.predict(scaled_x_test)\n",
    "r2_score=mean_squared_error(Y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65861470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdd727f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b898a270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ca2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf420408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89020c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8005de2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d513b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4354bb90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e056e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73d1117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae71517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4e5905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142699be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
